# **'데이터 생애주기(Data Lifecycle)'**

### 1단계: 핫(Hot) - 실시간 (1시간~1일)

* **상태:** 원시 데이터 그대로 보관.
* **처리:** 웹 대시보드에서 지금 당장의 수치를 보여주거나, 데이터브릭스가 ML로 이상 징후를 감지하는 단계입니다.
* **결과:** 시간이 지나면 **자동 삭제(TTL)** 됩니다.

### 2단계: 웜(Warm) - 최근 통계 (1년~3년)

* **상태:** 1분 또는 1시간 단위로 요약된 데이터.
* **처리:** "작년 이맘때 센서 평균값이 어땠지?" 같은 추세 분석용입니다.
* **결과:** 원본의 1/10,000 수준으로 압축되어 있으므로 수년 치를 쌓아도 용량이 얼마 안 됩니다.

### 3단계: 콜드(Cold) - 장기 보관 (5년~10년 이상)

* **상태:** 월간 보고서나 아주 가끔 필요한 백업 데이터.
* **처리:** 가장 저렴한 저장소(Archive Storage)로 옮겨둡니다.
* **결과:** 법적 규제나 정말 특수한 분석이 필요할 때만 꺼내 봅니다.
  

* * *

### 1. 실시간 데이터: "메모리 기반 캐시" (웹 백엔드)

* **방식:** 현재 활성 바스켓(~2,000개)만 메모리에 유지. signal=true 이벤트가 들어올 때마다 위치 업데이트.

* **이유:** signal=true만 전송되므로 전체 센서 데이터를 저장할 필요가 없습니다. 필요한 것은 "현재 바스켓이 어디에 있는가"뿐입니다.

* **비용:** 메모리 유지만으로 충분 (별도 저장소 불필요). 선택적으로 이벤트 로그만 저장.

### 2. 마스터 데이터: "영구 저장" (Azure SQL)

* **방식:** 센터 구역, 라인, 센서 위치, 사용자 정보 등 정적 설정값만 저장.

* **이유:** signal=true 이벤트는 이미 필터링되었으므로 원본 데이터 압축이 불필요합니다. 필요한 것은 "센서 위치가 어디인지"같은 메타데이터입니다.

* **용량:** 매우 적음 (마스터 데이터만 저장, 센서 로그 미포함).

### 3. 이벤트 로그: "선택적 저장" (분석용)

* **방식:** signal=true 이벤트를 선택적으로 Event Hub 또는 SQL에 저장. 필요시에만 조회 가능.

* **이유:** 사후 분석, 감사, 또는 고급 분석(Fabric)이 필요한 경우에만 로그 확보.
  
  

### 추천하는 비용구조 (Hybrid)

#### **① Azure Databricks (중급 사양 클러스터)**
* **비용:** 약 **$500 ~ $800 / 월** (예상)
* **설명:** 데이터가 계속 들어오므로 클러스터를 24시간 켜둬야 합니다. 연산 성능은 확실하지만, 켜져 있는 시간 자체가 비용이라 관리가 필요합니다.

#### **② MS Fabric (F2 ~ F4 등급)**
* **비용:** 약 **$300 ~ $600 / 월** (예상)
* **설명:** 가장 낮은 등급(F2)부터 시작할 수 있습니다. 페브릭은 '하나의 용량'을 사서 SQL, ML, 대시보드 모두가 나눠 쓰기 때문에 전체 프로젝트 비용으로는 오히려 저렴할 수 있습니다.

* * *

### 3. 현재 비용 구조 (signal=true 최적화 기준, 2026-01-30)

**이전에 고려했던 대규모 분석 솔루션들은 기존의 초당 1만 건 가정에 기반했습니다.**

signal=true 필터링으로 메시지 처리가 극도로 단순화되었으므로:
- **Azure Databricks:** 불필요 (메모리 캐시 + 선택적 Fabric만으로 충분)
- **대규모 Fabric:** 초대형 센터(superFc)에서만 선택사항
- **기본 비용 구조:** IoT Hub S1 + 백엔드 VM + SQL Database로 통일

**따라서 별도의 분석 솔루션 비용 검토는 필요시에만 진행하면 됩니다.**

* * *

### 1. 팩트 체크: Azure IoT Hub Event Hub를 통한 데이터 수신 방식 (현재 1/30 기준)

**변경 사항:** Kafka → 
**Azure IoT Hub + Event Hubs-compatible endpoint**로 변경됨

**최적화 (signal=true만 전송):**
```
센서 시뮬레이터 (IoT Edge Module)
    ↓
[필터링] signal=true인 센서 데이터만 선택
    ↓
Azure IoT Hub (AMQP)
    ↓ 
Event Hubs-compatible endpoint
    ↓
웹 백엔드 (eventhub_consumer.py) - 직접 수신 가능 ✅
```

**변경점:**
- 기존: 모든 센서 데이터 → Stream Analytics로 필터링 필요
- 최적화: 센서 시뮬레이터에서 이미 필터링된 데이터 전송 → Stream Analytics ✅
- 결과: 월간 메시지 98~99% 감소, 처리량 극도로 절감

실제로는 **센서 시뮬레이터(IoT Edge Module)가 signal=true인 이벤트만 Azure IoT Hub로 메시지를 전송**하고, **웹 백엔드가 Event Hub의 특정 '파티션(Partition)'을 실시간으로 지켜보고 있다가 데이터가 들어오는 대로 수신(Consume)** 하는 방식입니다.

이제 **Stream Analytics는 선택사항** (분석/집계 필요시에만 사용)이며, 모든 규모의 물류센터에서 **IoT Hub S1 Tier**로 충분합니다.

### 2. 현재 연동 구조 (signal=true 최적화): "IoT Edge → [필터링] → IoT Hub → Backend"

웹 백엔드는 이미 필터링된 signal=true 이벤트만 Event Hub에서 직접 수신합니다. **Stream Analytics는 선택사항입니다.**

#### **컴포넌트별 역할 정리**

| **단계**     | **도구/서비스**                | **연동 방식 및 역할**                                               |
| ---------- | ----------------------- | ------------------------------------------------------------ |
| **수집 & 필터링** | **센서 시뮬레이터 (IoT Edge Module)** | signal=true인 이벤트만 선별하여 IoT Hub로 전송 (AMQP).                  |
| **메시지 브로커** | **Azure IoT Hub (S1)** | 필터링된 센서 데이터의 중앙 채널 (Event Hubs 호환). 모든 규모 통합 가능.                      |
| **실시간 수신** | **웹 백엔드 (eventhub_consumer.py)** | **직접 처리.** signal=true 이벤트를 메모리 캐시에 저장. Stream Analytics 불필요. |
| **실시간 표출** | **React + Backend API** | 메모리 캐시의 현재 바스켓 위치를 WebSocket 또는 REST를 통해 실시간 화면 표시.   |
| **고급 분석** (선택) | **Azure Stream Analytics** | 필요시에만 5분 단위 집계, 병목 감지 등 수행.             |
| **장기 분석** (선택) | **Azure Fabric** | 초대형 센터에서만 도입. Power BI 리포트, 성능 추이 분석.                           |

### **Azure IoT Hub 상세 사양**

#### 프로토콜 및 통신

| **항목**      | **사양**                          |
| ----------- | ------------------------------- |
| **지원 프로토콜** | AMQP, MQTT, HTTPS              |
| **기본 프로토콜** | AMQP (IoT Hub ↔ 센서 시뮬레이터) |
| **메시지 포맷** | JSON (권장), 바이너리 지원         |
| **포트**      | 5671 (AMQP), 8883 (MQTT), 443 (HTTPS) |
| **암호화**    | TLS 1.2 필수, 연결 문자열 기반 인증 |

#### 확장성 및 성능

| **항목**      | **사양**                          |
| ----------- | ------------------------------- |
| **SKU 옵션**  | Free, S1, S2, S3               |
| **메시지 보존** | 1~90일 (기본 1일)                |
| **파티션**    | 자동 파티셔닝 (SKU별 최대값)      |
| **처리량 (S1)** | 월 400,000개 메시지, 400개/초   |
| **자동 스케일링** | Azure 관리 (별도 설정 불필요)   |
| **Event Hubs 호환** | ✅ Kafka Consumer API와 유사 |

#### 비용 구조 (한국 지역 기준, signal=true 최적화 후)

| **SKU** | **월간 메시지 한도** | **실제 사용 (센터별)** | **월 비용** | **용도** |
|--------|-------------------|------------------|-----------|--------|
| **Free** | 8,000 | mfc 2.1M | $0 | 개발/테스트, 소형 센터 |
| **S1** | 400,000 | **모든 규모 (2.1M ~ 48.6M)** ✅ | **~$100** | **모든 물류센터 (통합 사용)** |
| **S2** | 6M | (불필요) | ~$300 | 기존용 (현재 미사용) |
| **S3** | 300M | (불필요) | ~$900 | 기존용 (현재 미사용) |

**핵심 변화:**
- 기존: 규모별로 S1, S2, S3 선택 필요 (최대 $2,700/월)
- 최적화: **모든 규모에서 IoT Hub S1 + 선택사항인 Stream Analytics만** (기본 $100/월)
- 절감율: **71~93%** (규모별로 기존 $2,550 → $100~180로 감소)

#### 주요 특징

**✅ 장점**
- **관리형 서비스:** 인프라 운영 부담 없음
- **고가용성:** 99.9% SLA 보장
- **자동 확장:** 부하에 따른 자동 스케일링
- **보안:** Azure 네이티브 보안 (Microsoft Entra, Key Vault)
- **모니터링:** Application Insights 통합
- **비용 효율:** 사용량 기반 과금

**⚠️ 고려사항**
- signal=true 필터링이 센서 시뮬레이터에서 정확히 구현되어야 함
- 메모리 캐시 크기 (2,000 바스켓)를 규모에 맞게 조정 필요
- 이벤트 로그 저장 시 장기 비용 검토 필요



### **① 공간 토폴로지 뷰 (Topology Flow Map)**

* **구성:** 레일의 실제 연결 구조를 단순화한 회로도 형태의 맵.
* **핵심 요소:** 각 노드(연결점) 사이의 이동 속도를 실시간 선 굵기로 표현.
* **전문가 팁:** 단순히 "막혔다"가 아니라, **"어느 지점에서 유입이 급증해 뒤로 밀리고 있는지"** 화살표 애니메이션으로 시각화합니다.

### **② 버퍼 점유율 레이더 (Buffer Occupancy & Queue Depth)**

* **구성:** 레일 사이의 임시 적재 공간(Buffer)이 얼마나 찼는지 보여주는 수직 바 차트.
* **핵심 요소:** '임계치(Threshold)'를 설정하여 80% 이상 점유 시 즉각 점멸.
* **이유:** 병목은 보통 레일 자체가 아니라, 레일 끝의 **대기열(Queue)**에서 시작되기 때문입니다.

### **③ 병목 전이 타임라인 (Bottleneck Propagation Timeline)**

* **구성:** 시간 축에 따라 병목 발생 지점이 어떻게 이동했는지 보여주는 히트맵.
* **핵심 요소:** A구간 병목 발생 후 10분 뒤 B구간으로 정체가 전이되는 양상을 시각화.
* **이유:** 정체의 '근본 원인(Root Cause)' 지점을 찾아내기 위함입니다.

* * *

2. 추천 데이터 분석 (Advanced Analytics)

---------------------------------

데이터 엔지니어로서 단순 합계나 평균 이상의 가치를 줄 수 있는 분석 기법입니다.



### **① 흐름 안정성 지표 (Flow Stability Index)**

단순 TPH보다 **물동량의 변동성**을 분석합니다.

* **분석법:** 물동량의 표준편차를 평균으로 나눈 **변동계수($CV = \frac{\sigma}{\mu}$)** 산출.
* **목표:** $CV$ 값이 낮을수록 흐름이 매끄러운 것이며, 이 값이 튀면 설비 부하가 급증함을 의미합니다.



### **② 구간별 체류 시간 분석 (Dwell Time Analysis)**

박스가 특정 구간에 진입해서 나갈 때까지의 순수 소요 시간을 추적합니다.

* **분석법:** RFID나 바코드 스캔 데이터를 활용하여 구간별 **평균 체류 시간** 계산.
* **목표:** 설계된 속도 대비 실제 체류 시간이 긴 '저효율 구간'을 상시 발굴합니다.



### **③ 상관관계 분석 (Cross-Correlation Analysis)**

* **분석법:** 상류(Upstream) 유입량과 하류(Downstream) 정체 사이의 시간차(Lag time) 상관관계 분석.
* **목표:** "입고 레일에 박스가 100개 추가되면, 15분 뒤 포장 레일이 막힌다"는 인과관계를 공식화하여 예측 모델에 활용합니다.

* * *

## 요약: 데이터 엔지니어의 핵심 대시보드 전략

| **구분**  | **주요 내용**                | **기대 효과**        |
| ------- | ------------------------ | ---------------- |
| **시각화** | 물리적 배치 기반의 **실시간 흐름 맵**  | 직관적인 장애 지점 파악    |
| **알람**  | **예측 가동률** 기반의 사전 경보     | 사후 약방문식 대응 방지    |
| **분석**  | 구간별 **체류 시간 및 전이 경로** 분석 | 설비 개선의 근거 데이터 확보 |



### 1. 현재 아키텍처: signal=true 최적화 기반 (2026-01-30 기준)

**signal=true만 전송**하므로 실제 처리량은 극도로 절감되었습니다.
- mfc: 초당 ~20 메시지
- megaFc: 초당 ~300 메시지  
- superFc: 초당 ~450 메시지

따라서 기존의 대용량 처리 아키텍처(메달리온 + 람다)에서 **간결한 실시간 처리 모델**로 전환되었습니다.

#### ① Ingestion Layer (수집층) - 필터링된 데이터 수집

* **Azure IoT Hub (S1 Tier):** 센서 시뮬레이터에서 signal=true인 이벤트만 전송받습니다. 모든 물류센터 규모가 S1(월 400K 메시지)로 통합 가능합니다.

#### ② Hot Path (실시간/운영층) - "현재 바스켓 위치 추적"

* **웹 백엔드 (Python FastAPI):** eventhub_consumer.py가 Event Hub에서 signal=true 이벤트를 직접 수신하여 **메모리 기반 캐시(2,000 바스켓)**에 저장합니다. Stream Analytics 없이도 충분합니다.

* **Azure SQL Database:** 회원 정보, 물류센터 마스터 정보(구역 ID, 라인 배치, 센서 위치), 운영 설정값. 정적 데이터만 저장합니다.

#### ③ Cold/Warm Path (분석/이력층) - "추세 분석 및 성능 리포트" (선택사항)

* **Azure Stream Analytics (선택사항):** 실시간 집계가 필요한 경우에만 사용합니다. 예: 5분 단위 구간별 처리량, 병목 감지 등

* **Azure Fabric (선택사항):** 초대형 센터(superFc)에서 장기 분석이 필요한 경우만 도입합니다.
  * **OneLake:** 센서 이벤트 원본 저장
  * **KQL Database:** 실시간 성능 분석
  * **Power BI:** 주간/월간 리포트 대시보드

* * *

### 2. 저장소별 상세 데이터 매핑 (signal=true 최적화 기준)

**실제 구현:** 필터링된 센서 데이터만 처리하므로 인프라가 극도로 단순합니다.

| **분류**      | **저장소**              | **데이터 종류**                       | **용도**                   |
| ----------- | -------------------- | ------------------------------------- | ------------------------------ |
| **운영/마스터** (정적) | **Azure SQL**        | 사용자 정보, 구역/라인 배치, 센서 위치, 설정값 | ACID 트랜잭션 (마스터 데이터) |
| **실시간 추적** (메모리) | **웹 백엔드 메모리 캐시** | 현재 2,000 바스켓 위치 (메모리만 유지) | 대시보드 실시간 표시 |
| **이벤트 로그** (선택) | **Event Hub** 또는 **Azure SQL** | signal=true 이벤트 로그 (선택적 저장) | 사후 분석/감사 |
| **고급 분석** (선택) | **Azure Fabric** | 장기 성능 추이, BI 리포트 | 초대형 센터 분석용 (선택사항) |

* * *

### 최종 권장 구성 (signal=true 최적화)

**기본 (모든 센터 규모):**
- **메시지 수집:** Azure IoT Hub S1 ($100/월)
- **백엔드:** Azure VM B2s (2vCPU, 4GB) + Python FastAPI
- **운영/설정:** Azure SQL Database Serverless (2 vCore)
- **프론트엔드:** React (Canvas 기반 시각화)
- **총 기본 비용:** ~$180/월

**선택사항 (분석 필요시):**
- Stream Analytics: $300~500/월
- Azure Fabric (초대형 센터): $5,400+/월

### **백엔드 서버 인프라: Azure VM B2s 또는 App Service B1**
**선택 기준:**
* **소형 센터 (mfc, tc):** App Service B1 ($50/월, 자동 스케일)
* **중형 센터 (dc, megaFc):** VM B2s ($60/월, 더 많은 리소스)
* **초대형 센터 (superFc):** VM B4ms ($120/월, 고성능 처리)

**사양:**
* **OS**: Linux (비용 절감)
* **런타임**: Python 3.10+ (FastAPI + Uvicorn)
* **메모리**: 2,000 바스켓 캐시용 충분한 RAM


---

## 부하율 관리 (향후 개선)

**현재 상태:** signal=true 필터링으로 메시지 처리가 극도로 간단화되었으므로 부하 관리는 보조적입니다.

**향후 추가 가능 기능:**
- 구역별 바스켓 밀도 (현재 활성 바스켓 수 / 설계 용량)
- 라인별 처리량 추이 (최근 1시간 단위)
- 병목 감지 (처리 속도 저하 시 알림)

**기술 구현:**
- 메모리 캐시에서 실시간 계산
- WebSocket으로 대시보드 실시간 업데이트
- 임계값 초과시 Application Insights 로그

이를 위해서는 BasketMovement 클래스에 구역별/라인별 집계 기능 추가 필요합니다.

