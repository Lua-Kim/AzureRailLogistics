# **'데이터 생애주기(Data Lifecycle)'**

### 1단계: 핫(Hot) - 실시간 (1시간~1일)

* **상태:** 원시 데이터 그대로 보관.

* **처리:** 웹 대시보드에서 지금 당장의 수치를 보여주거나, 데이터브릭스가 ML로 이상 징후를 감지하는 단계입니다.

* **결과:** 시간이 지나면 **자동 삭제(TTL)** 됩니다.

### 2단계: 웜(Warm) - 최근 통계 (1년~3년)

* **상태:** 1분 또는 1시간 단위로 요약된 데이터.

* **처리:** "작년 이맘때 센서 평균값이 어땠지?" 같은 추세 분석용입니다.

* **결과:** 원본의 1/10,000 수준으로 압축되어 있으므로 수년 치를 쌓아도 용량이 얼마 안 됩니다.

### 3단계: 콜드(Cold) - 장기 보관 (5년~10년 이상)

* **상태:** 월간 보고서나 아주 가끔 필요한 백업 데이터.

* **처리:** 가장 저렴한 저장소(Archive Storage)로 옮겨둡니다.

* **결과:** 법적 규제나 정말 특수한 분석이 필요할 때만 꺼내 봅니다.
  
  

맞습니다! 제가 너무 정석적인 "빅데이터 저장" 관점에서만 말씀드렸네요. 사실 모든 원시 데이터를 무식하게 다 쌓는 건 예산 낭비고, 질문자님 말씀대로 **필요한 만큼만 순환(Rotation)**시키는 게 훨씬 지능적인 방식입니다.

그럼 질문자님의 **"안 무식한" 효율적 설계**를 딱 3단계로 정리해 드릴게요.

* * *

### 1. 원시 데이터: "1시간 순환" (Fabric OneLake)

* **방식:** 1시간이 지나면 옛날 데이터는 자동으로 밀려나고 새 데이터가 그 자리를 채웁니다. (마치 블랙박스 메모리 카드처럼요.)

* **이유:** 실시간 관제와 사고 직전 원인 분석에는 최근 1시간 데이터만 있으면 충분하기 때문입니다.

* **비용:** 18GB(1시간치) 정도면 저장 비용은 사실상 **0원**에 가깝습니다.

### 2. 통계 데이터: "영구 저장" (Azure SQL)

* **방식:** 원본이 삭제되기 전에, Flink나 Fabric이 **1분 단위로 요약(평균값, 최대값)**해서 SQL DB로 보냅니다.

* **이유:** "지난주 화요일 오후 2시 트래픽" 같은 흐름을 보려면 이 요약본이 필요합니다.

* **용량:** 1만 개 데이터가 1개로 압축되므로, 평생 쌓아도 용량이 얼마 안 됩니다.

### 3. 장애 로그: "이벤트 발생 시에만 저장"

* **방식:** 평소에는 버리다가, 센서 값이 임계치를 넘거나 에러가 났을 때만 그 구간의 원본을 따로 보관합니다.
  용
  
  

### 추천하는 비용구조 (Hybrid)

#### **① Azure Databricks (중급 사양 클러스터)**

* **비용:** 약 **$500 ~ $800 / 월** (예상)

* **설명:** 데이터가 계속 들어오므로 클러스터를 24시간 켜둬야 합니다. 연산 성능은 확실하지만, 켜져 있는 시간 자체가 비용이라 관리가 필요합니다.

#### **② MS Fabric (F2 ~ F4 등급)**

* **비용:** 약 **$300 ~ $600 / 월** (예상)

* **설명:** 가장 낮은 등급(F2)부터 시작할 수 있습니다. 페브릭은 '하나의 용량'을 사서 SQL, ML, 대시보드 모두가 나눠 쓰기 때문에 전체 프로젝트 비용으로는 오히려 저렴할 수 있습니다.

* * *

### 3. 데이터브릭스, 페브릭 비교

### 예상 견적 (초당 1만 건, 24시간 가동 시)

#### **① Azure Databricks (중급 사양 클러스터)**

* **비용:** 약 **$500 ~ $800 달러/ 월** (예상)

* **설명:** 데이터가 계속 들어오므로 클러스터를 24시간 켜둬야 합니다. 연산 성능은 확실하지만, 켜져 있는 시간 자체가 비용이라 관리가 필요합니다.

#### **② MS Fabric (F2 ~ F4 등급)**

* **비용:** 약 **$300 ~ $600 달러 / 월** (예상)

* **설명:** 가장 낮은 등급(F2)부터 시작할 수 있습니다. 페브릭은 '하나의 용량'을 사서 SQL, ML, 대시보드 모두가 나눠 쓰기 때문에 전체 프로젝트 비용으로는 오히려 저렴할 수 있습니다.

* **데이터브릭스가 비싸지는 이유:** 데이터브릭스 사용료 외에 데이터를 저장할 **Storage 비용**과 데이터를 옮기는 **네트워크 비용**이 별도로 붙습니다.

* **페브릭이 경제적인 이유:** **OneLake**라는 통합 저장소를 쓰기 때문에 데이터 복사 비용이 없고, 
  Power BI(시각화) 라이선스 등이 포함되어 있어 **'토탈 패키지'**로 보면 더 저렴합니다.

* * *

### 1. 팩트 체크: Kafka에서 데이터를 가져오는 방식

질문자님이 "어떤 요청을 해서 결과를 받아오나?"라고 하셨는데, 실제로는 **웹 백엔드가 Kafka의 특정 '토픽(Topic)'을 실시간으로 지켜보고 있다가 데이터가 들어오는 대로 낚아채는(Consume)** 방식입니다.

하지만 말씀하신 대로 1만 개의 원본 데이터를 웹 서버가 다 받아버리면 서버가 뻗어버립니다. 그래서 중간에 **Flink**가 반드시 필요합니다.

### 2. 현실적인 연동 구조: "필터링과 집계"

웹 서버는 Kafka의 `raw-data` 토픽을 보는 게 아니라, **Flink가 가공해서 다시 쏴준 `processed-data` 토픽**을 봐야 합니다.

* **원본 데이터 (10,000개/초):** Python 시뮬레이터 → Kafka (`raw-topic`)

* **Flink의 역할 (연산):** Kafka의 `raw-topic`을 읽어서 **"지금 병목이 발생한 라인이 어디인가?"**만 계산합니다. 1만 개 데이터가 Flink를 거치면 **병목 지점 5~10개 정보**로 압축됩니다.

* **결과 데이터 (수십 개/초):** Flink → Kafka (`alert-topic`)에 다시 저장.

* **웹 백엔드의 역할 (중계):** Kafka의 `alert-topic`만 구독합니다. 데이터량이 확 줄어들었기 때문에 웹 서버에 무리가 가지 않습니다.
  
  

| **단계**     | **도구**         | **연동 방식 및 역할**                                               |
| ---------- | -------------- | ------------------------------------------------------------ |
| **수집**     | **Kafka**      | 모든 센서 데이터의 중앙 고속도로.                                          |
| **실시간 연산** | **Flink**      | **핵심 두뇌.** 1초마다 1만 개를 읽어 병목 패턴(Complex Event Processing) 분석. |
| **실시간 표출** | **React**      | Flink가 요약한 정보를 웹 백엔드(WebSocket)를 통해 실시간으로 화면에 그림.            |
| **분석/배치**  | **Databricks** | Kafka의 원본을 가져와서 장기 통계 분석 및 머신러닝 모델 생성.                       |
| **최종 저장**  | **Azure SQL**  | Databricks나 Flink가 뽑아낸 **일일 리포트, 통계 지표** 등 최종 결과물 저장.        |

### **① 공간 토폴로지 뷰 (Topology Flow Map)**

* **구성:** 레일의 실제 연결 구조를 단순화한 회로도 형태의 맵.

* **핵심 요소:** 각 노드(연결점) 사이의 이동 속도를 실시간 선 굵기로 표현.

* **전문가 팁:** 단순히 "막혔다"가 아니라, **"어느 지점에서 유입이 급증해 뒤로 밀리고 있는지"** 화살표 애니메이션으로 시각화합니다.

### **② 버퍼 점유율 레이더 (Buffer Occupancy & Queue Depth)**

* **구성:** 레일 사이의 임시 적재 공간(Buffer)이 얼마나 찼는지 보여주는 수직 바 차트.

* **핵심 요소:** '임계치(Threshold)'를 설정하여 80% 이상 점유 시 즉각 점멸.

* **이유:** 병목은 보통 레일 자체가 아니라, 레일 끝의 **대기열(Queue)**에서 시작되기 때문입니다.

### **③ 병목 전이 타임라인 (Bottleneck Propagation Timeline)**

* **구성:** 시간 축에 따라 병목 발생 지점이 어떻게 이동했는지 보여주는 히트맵.

* **핵심 요소:** A구간 병목 발생 후 10분 뒤 B구간으로 정체가 전이되는 양상을 시각화.

* **이유:** 정체의 '근본 원인(Root Cause)' 지점을 찾아내기 위함입니다.

* * *

2. 추천 데이터 분석 (Advanced Analytics)

---------------------------------

데이터 엔지니어로서 단순 합계나 평균 이상의 가치를 줄 수 있는 분석 기법입니다.

### **① 흐름 안정성 지표 (Flow Stability Index)**

단순 TPH보다 **물동량의 변동성**을 분석합니다.

* **분석법:** 물동량의 표준편차를 평균으로 나눈 **변동계수($CV = \frac{\sigma}{\mu}$)** 산출.

* **목표:** $CV$ 값이 낮을수록 흐름이 매끄러운 것이며, 이 값이 튀면 설비 부하가 급증함을 의미합니다.

### **② 구간별 체류 시간 분석 (Dwell Time Analysis)**

박스가 특정 구간에 진입해서 나갈 때까지의 순수 소요 시간을 추적합니다.

* **분석법:** RFID나 바코드 스캔 데이터를 활용하여 구간별 **평균 체류 시간** 계산.

* **목표:** 설계된 속도 대비 실제 체류 시간이 긴 '저효율 구간'을 상시 발굴합니다.

### **③ 상관관계 분석 (Cross-Correlation Analysis)**

* **분석법:** 상류(Upstream) 유입량과 하류(Downstream) 정체 사이의 시간차(Lag time) 상관관계 분석.

* **목표:** "입고 레일에 박스가 100개 추가되면, 15분 뒤 포장 레일이 막힌다"는 인과관계를 공식화하여 예측 모델에 활용합니다.

* * *

3. 요약: 데이터 엔지니어의 핵심 대시보드 전략

---------------------------

| **구분**  | **주요 내용**                | **기대 효과**        |
| ------- | ------------------------ | ---------------- |
| **시각화** | 물리적 배치 기반의 **실시간 흐름 맵**  | 직관적인 장애 지점 파악    |
| **알람**  | **예측 가동률** 기반의 사전 경보     | 사후 약방문식 대응 방지    |
| **분석**  | 구간별 **체류 시간 및 전이 경로** 분석 | 설비 개선의 근거 데이터 확보 |
